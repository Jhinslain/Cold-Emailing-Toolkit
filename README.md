# SystÃ¨me de Scoring Lighthouse Multi-API

Ce systÃ¨me permet d'analyser en masse les performances web de sites en utilisant l'API Google PageSpeed Insights avec plusieurs clÃ©s API en parallÃ¨le.

## ğŸš€ FonctionnalitÃ©s

- Analyse des performances mobiles et SEO via Lighthouse
- Support des mÃ©triques CrUX (Core Web Vitals)
- Traitement parallÃ¨le avec 3 clÃ©s API
- Sauvegardes automatiques tous les 100 traitements
- Gestion robuste des erreurs
- Fusion automatique des rÃ©sultats

## ğŸ“‹ PrÃ©requis

- Node.js (v14 ou supÃ©rieur)
- Les dÃ©pendances npm listÃ©es dans `package.json`

## ğŸ“¦ Installation

1. Cloner le repository
2. Installer les dÃ©pendances :
```bash
npm install
```

## ğŸ”‘ Configuration des ClÃ©s API

Le systÃ¨me utilise 3 clÃ©s API Google PageSpeed Insights :
- `AIzaSyD0u3W7oJ_CjsZ9pTrdiXcBXrVgTHoyViU`
- `AIzaSyAUFbNE3eaj_KOG3K-3UEEbtiMziKOoChc`
- `AIzaSyD003NPDofDbJH1qLEqwEOSfQk8ZJBde10`

## ğŸ“Š Utilisation

### Format du fichier d'entrÃ©e

Le fichier CSV d'entrÃ©e doit contenir une colonne `Website` avec les URLs Ã  analyser.

### Lancer l'analyse

```bash
node master_script.js leads.csv
```

Le script va :
1. Diviser le fichier en 3 parties
2. Lancer 3 instances en parallÃ¨le
3. GÃ©nÃ©rer un fichier `leads_results.csv`

### Options du script principal (score_lighthouse.js)

```bash
node score_lighthouse.js --input <fichier> --output <fichier> --api-key <clÃ©> [options]

Options :
  --input, -i     Fichier CSV d'entrÃ©e (obligatoire)
  --output, -o    Fichier CSV de sortie (obligatoire)
  --api-key       ClÃ© API Google (obligatoire)
  --crux          Activer l'analyse CrUX
  --concurrency   Nombre de requÃªtes simultanÃ©es (dÃ©faut: 4)
```

## ğŸ“ˆ MÃ©triques analysÃ©es

### Lighthouse
- Performance mobile (score 0-100)
- SEO mobile (score 0-100)

### Core Web Vitals (si --crux activÃ©)
- LCP (Largest Contentful Paint)
- CLS (Cumulative Layout Shift)
- INP (Interaction to Next Paint)

## ğŸ’¾ Sauvegardes

- Sauvegardes automatiques tous les 100 traitements
- Format : `results_backup_XXX.csv`
- En cas d'erreur, le script tente de sauvegarder l'Ã©tat actuel

## âš ï¸ Limitations

- Maximum 4 requÃªtes par seconde par clÃ© API
- Les URLs doivent Ãªtre valides et accessibles
- Format CSV requis pour l'entrÃ©e/sortie

## ğŸ” DÃ©tails techniques

### Structure des fichiers
- `master_script.js` : Script principal de distribution
- `score_lighthouse.js` : Script d'analyse individuel
- Fichiers temporaires : `temp_input_X.csv`, `temp_output_X.csv`

### Gestion des erreurs
- Logs dÃ©taillÃ©s pour chaque instance
- Sauvegardes automatiques
- Nettoyage des fichiers temporaires

## ğŸ“ Exemple de sortie

```csv
Website,psi_mobile_score,psi_seo_score,lcp_p75_ms,cls_p75,inp_p75_ms,custom_hook
https://example.com,85,90,1200,0.1,200,""
https://slow-site.com,45,75,3500,0.3,450,"Google Ã©value votre site mobile Ã  seulement 45/100 de performance..."
```

## ğŸ”„ Reprise aprÃ¨s erreur

En cas d'erreur :
1. Le script crÃ©e une sauvegarde de l'Ã©tat actuel
2. Les fichiers temporaires sont conservÃ©s
3. Relancer le script avec le dernier fichier de sauvegarde

## ğŸ“Š Monitoring

Les logs incluent :
- Progression en temps rÃ©el
- Erreurs dÃ©taillÃ©es
- Statistiques de traitement
- Ã‰tat des sauvegardes

# Script de Division de Fichier CSV

Ce script permet de diviser un fichier CSV volumineux en plusieurs fichiers plus petits, tout en conservant les en-tÃªtes dans chaque fichier.

## PrÃ©requis

- Node.js installÃ© sur votre systÃ¨me
- Les dÃ©pendances npm installÃ©es

## Installation

1. Installez les dÃ©pendances nÃ©cessaires :
```bash
npm install
```

## Utilisation

1. Placez votre fichier CSV Ã  diviser (nommÃ© `leadsFull.csv`) dans le mÃªme dossier que le script
2. ExÃ©cutez le script :
```bash
node split_csv.js
```

## Fonctionnement

Le script va :
- Lire le fichier `leadsFull.csv`
- CrÃ©er un dossier `output`
- Diviser le fichier en morceaux de 600 lignes
- GÃ©nÃ©rer des fichiers `leads1.csv`, `leads2.csv`, etc. dans le dossier `output`
- Conserver les en-tÃªtes du fichier original dans chaque nouveau fichier

## Personnalisation

Si vous souhaitez modifier la taille des morceaux, vous pouvez modifier la constante `CHUNK_SIZE` dans le fichier `split_csv.js` (par dÃ©faut : 600 lignes). 